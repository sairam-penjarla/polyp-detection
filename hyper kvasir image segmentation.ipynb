{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 18:19:13.927214: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "# import skimage.io as io\n",
    "# import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "# import skimage.io as io\n",
    "# import skimage.transform as trans\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "# from sklearn.metrics import jaccard_score\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800, 100, 100, 100, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"Hyper-Kvasir classification/unet_data\"\n",
    "train_path = dataset + \"/Train\"\n",
    "val_path = dataset + \"/Val\"\n",
    "test_path = dataset + \"/Test\"\n",
    "\n",
    "\n",
    "train_images_path = train_path + \"/images\"\n",
    "train_masks_path = train_path + \"/masks\"\n",
    "val_images_path = val_path + \"/images\"\n",
    "val_masks_path = val_path + \"/masks\"\n",
    "test_images_path = test_path + \"/images\"\n",
    "test_masks_path = test_path + \"/masks\"\n",
    "\n",
    "len(os.listdir((train_images_path))), len(os.listdir((train_masks_path))), len(os.listdir((val_images_path))), len(os.listdir((val_masks_path))), len(os.listdir((test_images_path))), len(os.listdir((test_masks_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(train_images_path), shutil.rmtree(train_masks_path)\n",
    "# shutil.rmtree(val_images_path), shutil.rmtree(val_masks_path)\n",
    "# shutil.rmtree(test_images_path), shutil.rmtree(test_masks_path)\n",
    "\n",
    "# os.mkdir(train_images_path), os.mkdir(train_masks_path)\n",
    "# os.mkdir(val_images_path), os.mkdir(val_masks_path)\n",
    "# os.mkdir(test_images_path), os.mkdir(test_masks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in os.listdir('Hyper-Kvasir classification/unet_data/data/images'):\n",
    "#     shutil.copy('Hyper-Kvasir classification/unet_data/data/images/'+i, 'Hyper-Kvasir classification/unet_data/Train/images')\n",
    "#     shutil.copy('Hyper-Kvasir classification/unet_data/data/masks/'+i, 'Hyper-Kvasir classification/unet_data/Train/masks')\n",
    "# for i in os.listdir('Hyper-Kvasir classification/unet_data/data/masks'):\n",
    "#     shutil.copy('Hyper-Kvasir classification/unet_data/data/images/'+i, 'Hyper-Kvasir classification/unet_data/Train/images')\n",
    "#     shutil.copy('Hyper-Kvasir classification/unet_data/data/masks/'+i, 'Hyper-Kvasir classification/unet_data/Train/masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in os.listdir('Hyper-Kvasir classification/unet_data/Train/images')[:100]:\n",
    "#     shutil.move('Hyper-Kvasir classification/unet_data/Train/images/'+j, 'Hyper-Kvasir classification/unet_data/Val/images')\n",
    "#     shutil.move('Hyper-Kvasir classification/unet_data/Train/masks/'+j, 'Hyper-Kvasir classification/unet_data/Val/masks')\n",
    "# for l in os.listdir('Hyper-Kvasir classification/unet_data/Train/images')[:100]:\n",
    "#     shutil.move('Hyper-Kvasir classification/unet_data/Train/images/'+l, 'Hyper-Kvasir classification/unet_data/Test/images')\n",
    "#     shutil.move('Hyper-Kvasir classification/unet_data/Train/masks/'+l, 'Hyper-Kvasir classification/unet_data/Test/masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800, 100, 100, 100, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(os.listdir((train_images_path))), len(os.listdir((train_masks_path))), len(os.listdir((val_images_path))), len(os.listdir((val_masks_path))), len(os.listdir((test_images_path))), len(os.listdir((test_masks_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_generator():\n",
    "    train_images = os.listdir(train_images_path)\n",
    "    train_masks = os.listdir(train_masks_path)\n",
    "    while True:\n",
    "        for i in range(len(train_images)):\n",
    "            img = cv2.imread(train_images_path + \"/\" + train_images[i])\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            img = img/255\n",
    "            mask = cv2.imread(train_masks_path + \"/\" + train_images[i], 0)\n",
    "            mask = cv2.resize(mask, (256, 256))\n",
    "            mask = mask/255\n",
    "            mask = np.expand_dims(mask, axis = 2)\n",
    "            yield (img, mask)\n",
    "def test_data_generator():\n",
    "    val_images = os.listdir(val_images_path)\n",
    "    val_masks = os.listdir(val_masks_path)\n",
    "    while True:\n",
    "        for i in range(len(val_images)):\n",
    "            original_img = cv2.imread(val_images_path + \"/\" + val_images[i])\n",
    "            img = cv2.resize(original_img, (256, 256))\n",
    "            img = img/255\n",
    "            original_mask = cv2.imread(val_masks_path + \"/\" + val_images[i], 0)\n",
    "            mask = cv2.resize(original_mask, (256, 256))\n",
    "            mask = mask/255\n",
    "            mask = np.expand_dims(mask, axis = 2)\n",
    "            yield (original_img, original_mask, img, mask)\n",
    "def val_data_generator():\n",
    "    test_images = os.listdir(test_images_path)\n",
    "    test_masks = os.listdir(test_masks_path)\n",
    "    while True:\n",
    "        for i in range(len(test_images)):\n",
    "            img = cv2.imread(test_images_path + \"/\" + test_images[i])\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            img = img/255\n",
    "            mask = cv2.imread(test_masks_path + \"/\" + test_images[i], 0)\n",
    "            mask = cv2.resize(mask, (256, 256))\n",
    "            mask = mask/255\n",
    "            mask = np.expand_dims(mask, axis = 2)\n",
    "            yield (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_inputs = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "######################################################################################################################################################\n",
    "Encoder_1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(unet_inputs)\n",
    "Encoder_1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Encoder_1)\n",
    "P1 = MaxPooling2D(pool_size=(2, 2))(Encoder_1)\n",
    "########################################################################################################################\n",
    "Encoder_2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(P1)\n",
    "Encoder_2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Encoder_2)\n",
    "P2 = MaxPooling2D(pool_size=(2, 2))(Encoder_2)\n",
    "##########################################################################################\n",
    "Encoder_3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(P2)\n",
    "Encoder_3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Encoder_3)\n",
    "P3 = MaxPooling2D(pool_size=(2, 2))(Encoder_3)\n",
    "############################################################\n",
    "Encoder_4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(P3)\n",
    "Encoder_4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Encoder_4)\n",
    "Dropout_layer_1 = Dropout(0.1)(Encoder_4)\n",
    "P4 = MaxPooling2D(pool_size=(2, 2))(Dropout_layer_1)\n",
    "##############################\n",
    "Encoder_5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(P4)\n",
    "Encoder_5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Encoder_5)\n",
    "Dropout_layer_2 = Dropout(0.1)(Encoder_5)\n",
    "##############################\n",
    "up_sample_6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(Dropout_layer_2))\n",
    "Conc_6 = concatenate([Dropout_layer_1,up_sample_6], axis = 3)\n",
    "Decoder_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Conc_6)\n",
    "Decoder_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Decoder_1)\n",
    "############################################################\n",
    "up_sample_7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(Decoder_1))\n",
    "Conc_7 = concatenate([Encoder_3,up_sample_7], axis = 3)\n",
    "Decoder_2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Conc_7)\n",
    "Decoder_2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Decoder_2)\n",
    "##########################################################################################\n",
    "up_sample_8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(Decoder_2))\n",
    "Conc_8 = concatenate([Encoder_2,up_sample_8], axis = 3)\n",
    "Decoder_3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Conc_8)\n",
    "Decoder_3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Decoder_3)\n",
    "########################################################################################################################\n",
    "up_sample_9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(Decoder_3))\n",
    "Conc_9 = concatenate([Encoder_1,up_sample_9], axis = 3)\n",
    "Decoder_4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Conc_9)\n",
    "Decoder_4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Decoder_4)\n",
    "######################################################################################################################################################\n",
    "Decoder_4 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(Decoder_4)\n",
    "Unet_outputs = Conv2D(1, 1, activation = 'sigmoid')(Decoder_4)\n",
    "\n",
    "model = tf.keras.Model(unet_inputs, Unet_outputs)\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model_checkpoint = ModelCheckpoint('polyp_UNET.hdf5', monitor='loss',verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, gen_x): \n",
    "    batch_features = [] \n",
    "    batch_labels = []\n",
    "    for i in range(batch_size):\n",
    "        x_train, y_train = next(gen_x)\n",
    "        batch_features.append(x_train)\n",
    "        batch_labels.append(y_train)\n",
    "    batch_features = np.array(batch_features)\n",
    "    batch_labels = np.array(batch_labels)\n",
    "    batch_labels = tf.cast(batch_labels, tf.float32)\n",
    "    return batch_features, batch_labels\n",
    "x_train, y_train = batch_generator(300, train_data_generator())\n",
    "history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=10, \n",
    "        steps_per_epoch=200, \n",
    "        validation_data=batch_generator(300, val_data_generator()), \n",
    "        validation_freq=1, \n",
    "        callbacks=[model_checkpoint],\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"polyp_UNET.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_similarity_score=[]\n",
    "for i in range(100):\n",
    "    original_img, original_mask, X, y_true = next(test_data)\n",
    "    y_pred = model.predict(np.expand_dims(X,0))\n",
    "    _,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\n",
    "    y_pred = (y_pred_thr/255).astype(int)\n",
    "    \n",
    "    y_pred_original = cv2.resize(y_pred.astype(float), (original_img.shape[1],original_img.shape[0]), interpolation= cv2.INTER_LINEAR)\n",
    "    # similarity_score = jaccard_score(original_mask[:,:,0]//255,y_pred_original.astype(int), average=\"micro\")\n",
    "    # validation_similarity_score.append(similarity_score)\n",
    "    if i < 5:\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(original_img[...,::-1], 'gray', interpolation='none')\n",
    "        plt.imshow(original_mask/255.0, 'jet', interpolation='none', alpha=0.4)\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(original_img[...,::-1], 'gray', interpolation='none')\n",
    "        plt.imshow(y_pred_original/255.0, 'jet', interpolation='none', alpha=0.4)\n",
    "        plt.show()\n",
    "# similarity_score_mean = validation_similarity_score.mean()\n",
    "# print(\"Mean validation Jaccard (on original data):\", similarity_score_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3504088a3f525b79f6a4929f0bff6e509abe0ae4c8a401e3e1e999e38e0af3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
